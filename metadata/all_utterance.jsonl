{
  "Name": "all_utterance.jsonl â€” Combined utterance scenarios (AssetOpsBench)",
  "Labeled": "Yes (scenario-level expected outputs present in `characteristic_form` for many records)",
  "Time Series": "No (this file contains scenario/utterance records that reference time-series data and tools; it is not raw telemetry)",
  "Data Source": "IBM/AssetOpsBench GitHub repository",
  "Missing Values": {
    "total_missing_cells": 302,
    "total_cells": 987,
    "missing_percentage": "30.598%"
  },
  "Dataset Characteristics": "A combined collection of multi-domain scenario utterances (IoT discovery/data queries, failure-mode reasoning, TSFM model & forecasting queries, work-order/event queries, and other multi-/single-agent prompts). Each record typically contains an id, optional type, textual prompt, category, and a `characteristic_form` describing the expected agent behavior or output. Designed to evaluate agent pipelines across retrieval, forecasting, anomaly detection, and maintenance decision tasks.",
  "Feature Type": "Categorical (id, type, category), Text (text, characteristic_form), Boolean/flag fields (e.g., deterministic), optional small structured fields (notes)",
  "Associated Tasks": "Knowledge-query evaluation, prompt-based agent benchmarking, tool/agent orchestration testing (IoTAgent, TSFMAgent, workorder tooling), retrieval & file-referencing, time-series forecasting/anomaly workflows, maintenance/work-order recommendation",
  "Number of Instances": 141,
  "Number of Features": 7,
  "Date Donated": "TO_FILL_BY_USER",
  "Source": "https://github.com/IBM/AssetOpsBench",
  "Summary": "141 scenario utterances (combined) used in AssetOpsBench to evaluate multi-agent and single-agent behavior across IoT, TSFM, workorder, failure-mode, and other operational tasks. Many records include deterministic expected outputs in `characteristic_form` to enable automated validation.",
  "Description": "This JSONL file (`all_utterance.jsonl`) aggregates 141 scenario records drawn from the AssetOpsBench benchmark. Entries span IoT data discovery, telemetry retrieval requests, time-series forecasting and anomaly detection prompts, failure-mode and sensor-relevance queries, and maintenance/work-order decision scenarios. Typical evaluation requires the agent to (1) identify correct assets/sites/time windows, (2) call appropriate tools or reference files, (3) run TSFM or anomaly detectors where requested, and (4) return or reference result files without hallucination. The dataset contains many instructional prompts intended to test correctness, reproducibility, and safe use of domain tools.",
  "Additional Tags": [
    "scenarios",
    "jsonl",
    "multi-agent",
    "IoT",
    "TSFM",
    "workorder",
    "failure-modes",
    "benchmark",
    "assetopsbench"
  ],
  "References": [
    {
      "Text": "AssetOpsBench - GitHub (repo)",
      "Link": "https://github.com/IBM/AssetOpsBench"
    }
  ]
}
