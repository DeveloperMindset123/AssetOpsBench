{
  "Name": "end2end_utterance.json â€” Multi-agent end-to-end utterance scenarios (AssetOpsBench)",
  "Labeled": "Yes (scenario-level expected outcomes present in `characteristic_form`)",
  "Time Series": "No (this file contains scenario/utterance records that reference time-series datasets; it is not raw telemetry)",
  "Data Source": "IBM/AssetOpsBench GitHub repository",
  "Missing Values": {
    "total_missing_cells": 44,
    "total_cells": 252,
    "missing_percentage": "17.460%"
  },
  "Dataset Characteristics": "A collection of multi-agent 'end-to-end' utterance scenarios used to evaluate agent behavior for retrieval, forecasting, and anomaly-detection workflows. Each record contains a scenario id, textual prompt/question, category, and a `characteristic_form` describing the expected agent actions and outputs. Contains realistic instruction-style prompts that reference assets, sites, sensors, and time windows.",
  "Feature Type": "Categorical (id, type, category), Text (text, characteristic_form), small structured fields (e.g., type flags)",
  "Associated Tasks": "Knowledge-query evaluation, agent pipeline validation, prompt-based testing, NLP parsing of scenario instructions, task routing for multi-agent systems",
  "Number of Instances": 42,
  "Number of Features": 6,
  "Date Donated": "TO_FILL_BY_USER",
  "Source": "https://github.com/IBM/AssetOpsBench",
  "Summary": "42 scenario utterances (end-to-end multi-agent tasks) for AssetOpsBench. Scenarios ask agents to retrieve telemetry, run TSFM/IoT agents, detect anomalies or forecast sensor data, and save/return analysis results.",
  "Description": "This JSON file (`end2end_utterance.json`) contains 42 scenario records used as part of the AssetOpsBench benchmark. Each record guides an agent through an end-to-end task (e.g., fetch Chiller 6 tonnage for a given week, run anomaly detection, save results). The `characteristic_form` field describes expected agent calls (IoTAgent, TSFMAgent), required variables (asset, site, timeframe), and the expected outputs. Use this file to evaluate agent correctness, non-hallucination, and proper use of domain-specific tools.",
  "Additional Tags": [
    "scenarios",
    "multi-agent",
    "benchmark",
    "NLP",
    "instructions",
    "assetopsbench",
    "end-to-end"
  ],
  "References": [
    {
      "Text": "AssetOpsBench - GitHub (repo)",
      "Link": "https://github.com/IBM/AssetOpsBench"
    }
  ]
}
